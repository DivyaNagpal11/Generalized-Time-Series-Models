{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import create_template_model as CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports =\"\"\"\n",
    "import statsmodels.api as sm\n",
    "import holidays\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Class Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"SARIMAX\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define Parameters for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param = \"param\"\n",
    "\n",
    "input_params = f\"\"\"\n",
    "    self.parameters_list = kwargs.get('parameters_list',None)\n",
    "\"\"\"\n",
    "\n",
    "init_function = f\"\"\"\n",
    "def __init__(self,**kwargs):\n",
    "\n",
    "    #input parameters\n",
    "\n",
    "    self.train,self.test = kwargs.get('train'),kwargs.get('test')       \n",
    "    self.random_state = kwargs.get('random_state',1)\n",
    "    self.target_dates = kwargs.get('target_dates')\n",
    "    self.target_value = kwargs.get('target_value')\n",
    "    self.target_items = kwargs.get('target_items')\n",
    "    {input_params}\n",
    "    self.n_periods = kwargs.get('n_periods',3)\n",
    "\n",
    "    #output values\n",
    "    self.fitted_values = pd.DataFrame()\n",
    "    self.test_prediction = pd.DataFrame()\n",
    "    self.unseen_prediction = pd.DataFrame()        \n",
    "    self.apes = []\n",
    "    self.run_model()\n",
    "    del self.train,self.test\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit method specific to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_method = f\"\"\"sm.tsa.statespace.SARIMAX(data,exog=np.asarray(exog_data),order=(param[0],param[1],param[2]),\n",
    "                                            seasonal_order=(param[3],param[4],param[5],param[6])).fit(disp=-1)\n",
    "\"\"\"\n",
    "\n",
    "fit_function = f\"\"\"\n",
    "def fit(self,data,exog_data,param=None):\n",
    "        \n",
    "    ###########\n",
    "    #  Fit funtion will fit your train data and return model\n",
    "    ###########\n",
    "    return {fit_method}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_script = None\n",
    "predict_method = \"model.predict(exog=exog_data,start=start,end=start+n_periods-1)\"\n",
    "predict_function =f\"\"\"\n",
    "def predict(self,model,exog_data,start,n_periods):\n",
    "    return {predict_method} \n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitted script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_data = f\"model.fittedvalues[param[6]+param[1]:]\"\n",
    "fitted_function =f\"\"\"\n",
    "def fitted_data(self,model,param=None):\n",
    "    return {fitted_data} \n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_functions = \"\"\"\n",
    "def split_train_test(self,subset_df):\n",
    "    return subset_df[:-3],subset_df[-3:]\n",
    "\n",
    "def mean_absolute_percentage_error(self,y_true,y_pred):\n",
    "    return np.mean(np.abs(np.subtract(y_true,y_pred)/y_true))*100  \n",
    "\n",
    "def calculate_apes(self):\n",
    "    for i,j in zip(self.test[self.target_value].values.flatten(),self.test_prediction.values.flatten()):            \n",
    "        self.apes.append(self.mean_absolute_percentage_error(i,j))\n",
    "\n",
    "def forecast_exogs(self,val_set):\n",
    "\n",
    "    max_date = val_set.index.max()\n",
    "    unseen_dates = pd.DataFrame()\n",
    "    unseen_dates[self.target_dates] = pd.date_range(max_date+pd.tseries.offsets.MonthEnd(n=1),\n",
    "              max_date+pd.tseries.offsets.MonthEnd(n=self.n_periods),freq='M')\n",
    "\n",
    "    start_year = val_set.index.max().year\n",
    "    end_year = start_year+2\n",
    "    us_holidays=[]\n",
    "    for date in holidays.UnitedStates(years=range(start_year,end_year)).items():\n",
    "        us_holidays.append([str(date[0]),date[1]])\n",
    "\n",
    "    us_holidays=pd.DataFrame(us_holidays,columns=[self.target_dates,'holiday'])\n",
    "    us_holidays=pd.DataFrame(us_holidays,columns=[self.target_dates,'holiday'])\n",
    "    us_holidays[self.target_dates]=pd.to_datetime(us_holidays[self.target_dates])\n",
    "    us_holidays.holiday=us_holidays.holiday.astype(str)\n",
    "    us_holidays['minor_holiday']=0\n",
    "    minor_holidays = ['Martin Luther King, Jr. Day' ,\"Washington's Birthday\" ,'Columbus Day' ,'Veterans Day'] \n",
    "    us_holidays.loc[us_holidays.holiday.isin(minor_holidays),'minor_holiday']=1\n",
    "    us_holidays['major_holiday']=0\n",
    "    major_holidays = [\"New Year's Day\" ,\"Christmas Day\",'Thanksgiving','Memorial Day','Labor Day','Independence Day'] \n",
    "    us_holidays.loc[us_holidays.holiday.isin(major_holidays),'major_holiday']=1\n",
    "    us_holidays['observed_holiday']=0\n",
    "    observed =  us_holidays.holiday.apply(lambda row: True if row[1].endswith(\"(Observed)\") else False)\n",
    "    us_holidays.loc[observed,'observed_holiday']=1\n",
    "    us_holidays = us_holidays.convert_dtypes()\n",
    "    us_holidays.sort_values(self.target_dates).reset_index(drop=True,inplace=True)\n",
    "    us_holidays = us_holidays.set_index(self.target_dates).resample('M').sum().reset_index()\n",
    "\n",
    "    return pd.merge(unseen_dates,us_holidays,on=self.target_dates,how='left')[['minor_holiday','major_holiday','observed_holiday']]\n",
    "\n",
    "def optimize_SARIMAX(self,parameters_list,train_set,val_set,exog_columns):\n",
    "\n",
    "    val_set1 = val_set.copy()\n",
    "    val_set=val_set[self.target_value].to_numpy()\n",
    "    results=[]\n",
    "    best_adj_mape = float('inf')\n",
    "#         self.train = self.train.astype(float)\n",
    "    for param in parameters_list:\n",
    "        try:\n",
    "            model=self.fit(train_set[self.target_value].astype(float),train_set.loc[:,exog_columns].astype(float).reset_index(drop=True),param)\n",
    "            fore1=self.predict(model,val_set1.loc[:,exog_columns].astype(float).reset_index(drop=True),self.train.shape[0],self.n_periods)\n",
    "            fore=np.array(fore1)\n",
    "\n",
    "            y_true=np.array(list(train_set[param[6]+param[1]:][self.target_value]))\n",
    "            y_pred=np.array(list(model.fittedvalues[param[6]+param[1]:]))\n",
    "            train_mape=round((self.mean_absolute_percentage_error(y_true,y_pred)),2)\n",
    "            val_mape=round((self.mean_absolute_percentage_error(val_set,fore)),2)\n",
    "            adj_mape = train_mape*len(y_true)/(len(y_true)+len(val_set))+val_mape*len(val_set)/(len(y_true)+len(val_set))\n",
    "            if adj_mape <= best_adj_mape:\n",
    "                best_adj_mape=adj_mape\n",
    "                best_model = model    \n",
    "            results.append([param,model.aic,train_mape,val_mape,adj_mape,fore])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    result_table=pd.DataFrame(results)\n",
    "\n",
    "    result_table.columns=['parameters','aic','train_mape','val_mape','adj_mape','test_prediction']\n",
    "    val_results = result_table.sort_values(by='adj_mape',ascending=True).reset_index(drop=True).copy()\n",
    "    test_predict = val_results.loc[:5]['test_prediction'].apply(lambda row: pd.Series(row).T).mean()\n",
    "\n",
    "    self.test_prediction = pd.DataFrame(test_predict.values.flatten(),self.test.index,columns=[self.target_value])\n",
    "    return val_results, best_model\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Models and storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_script = f\"\"\"\n",
    "def run_model(self):\n",
    "    exog_columns =  ['minor_holiday','major_holiday', 'observed_holiday']\n",
    "    val_results, best_model = self.optimize_SARIMAX(self.parameters_list,self.train,self.test,exog_columns)\n",
    "    #Model running for test prediction\n",
    "    fitted_val_list=[]\n",
    "\n",
    "    actual_data = self.train.append(self.test)\n",
    "    for param in val_results['parameters'].loc[:5]:\n",
    "        try:\n",
    "\n",
    "            model = self.fit(actual_data[self.target_value],actual_data.loc[:,exog_columns].astype(float).reset_index(drop=True),param)\n",
    "            fore_test=self.predict(model,self.forecast_exogs(self.test).astype(float).reset_index(drop=True),actual_data.shape[0],self.n_periods)\n",
    "            fitted_val_list.append(fore_test.values.flatten())\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    fitted_val=pd.DataFrame(fitted_val_list,columns=np.arange(1,self.n_periods+1))\n",
    "    fitted_mean=[]\n",
    "    for i in np.arange(1,self.n_periods+1):\n",
    "        fitted_mean.append(fitted_val[i].mean())\n",
    "\n",
    "    unseen_index = pd.date_range(self.test.index[-1]+pd.tseries.offsets.MonthEnd(n=1),\n",
    "          self.test.index[-1]+pd.tseries.offsets.MonthEnd(n=self.n_periods),freq='M')\n",
    "\n",
    "    self.unseen_prediction = pd.DataFrame(fitted_mean,unseen_index,columns=[self.target_value])\n",
    "\n",
    "    #Calculate apes for each test prediction        \n",
    "    self.calculate_apes()\n",
    "    self.train_model_params = val_results['parameters'].loc[:5]            \n",
    "    self.test_model_params = val_results['parameters'].loc[:5]\n",
    "    self.train_mape = val_results['train_mape'].loc[:5].mean()  \n",
    "    self.test_mape = val_results['val_mape'].loc[:5].mean()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "template_dict = dict(imports=imports,class_name=class_name,init_function=init_function,\n",
    "                         fit_function=fit_function,fitted_function=fitted_function,predict_function=predict_function,\n",
    "                        additional_functions=additional_functions,run_script=run_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT.render_template(template_dict=template_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Import files\n",
      "\n",
      "\n",
      "import statsmodels.api as sm\n",
      "import holidays\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "#Model class\n",
      "class SARIMAX:\n",
      "\n",
      "  \n",
      "\n",
      "    def __init__(self,**kwargs):\n",
      "\n",
      "        #input parameters\n",
      "\n",
      "        self.train,self.test = kwargs.get('train'),kwargs.get('test')       \n",
      "        self.random_state = kwargs.get('random_state',1)\n",
      "        self.target_dates = kwargs.get('target_dates')\n",
      "        self.target_value = kwargs.get('target_value')\n",
      "        self.target_items = kwargs.get('target_items')\n",
      "        \n",
      "        self.parameters_list = kwargs.get('parameters_list',None)\n",
      "\n",
      "        self.n_periods = kwargs.get('n_periods',3)\n",
      "\n",
      "        #output values\n",
      "        self.fitted_values = pd.DataFrame()\n",
      "        self.test_prediction = pd.DataFrame()\n",
      "        self.unseen_prediction = pd.DataFrame()        \n",
      "        self.apes = []\n",
      "        self.run_model()\n",
      "        del self.train,self.test\n",
      "\n",
      "\n",
      "\n",
      "    def fit(self,data,exog_data,param=None):\n",
      "            \n",
      "        ###########\n",
      "        #  Fit funtion will fit your train data and return model\n",
      "        ###########\n",
      "        return sm.tsa.statespace.SARIMAX(data,exog=np.asarray(exog_data),order=(param[0],param[1],param[2]),\n",
      "                                                seasonal_order=(param[3],param[4],param[5],param[6])).fit(disp=-1)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    def fitted_data(self,model,param=None):\n",
      "        return model.fittedvalues[param[6]+param[1]:] \n",
      "\n",
      "\n",
      "\n",
      "    def predict(self,model,exog_data,start,n_periods):\n",
      "        return model.predict(exog=exog_data,start=start,end=start+n_periods-1) \n",
      "\n",
      "\n",
      "\n",
      "    def split_train_test(self,subset_df):\n",
      "        return subset_df[:-3],subset_df[-3:]\n",
      "\n",
      "    def mean_absolute_percentage_error(self,y_true,y_pred):\n",
      "        return np.mean(np.abs(np.subtract(y_true,y_pred)/y_true))*100  \n",
      "\n",
      "    def calculate_apes(self):\n",
      "        for i,j in zip(self.test[self.target_value].values.flatten(),self.test_prediction.values.flatten()):            \n",
      "            self.apes.append(self.mean_absolute_percentage_error(i,j))\n",
      "\n",
      "    def forecast_exogs(self,val_set):\n",
      "\n",
      "        max_date = val_set.index.max()\n",
      "        unseen_dates = pd.DataFrame()\n",
      "        unseen_dates[self.target_dates] = pd.date_range(max_date+pd.tseries.offsets.MonthEnd(n=1),\n",
      "                  max_date+pd.tseries.offsets.MonthEnd(n=self.n_periods),freq='M')\n",
      "\n",
      "        start_year = val_set.index.max().year\n",
      "        end_year = start_year+2\n",
      "        us_holidays=[]\n",
      "        for date in holidays.UnitedStates(years=range(start_year,end_year)).items():\n",
      "            us_holidays.append([str(date[0]),date[1]])\n",
      "\n",
      "        us_holidays=pd.DataFrame(us_holidays,columns=[self.target_dates,'holiday'])\n",
      "        us_holidays=pd.DataFrame(us_holidays,columns=[self.target_dates,'holiday'])\n",
      "        us_holidays[self.target_dates]=pd.to_datetime(us_holidays[self.target_dates])\n",
      "        us_holidays.holiday=us_holidays.holiday.astype(str)\n",
      "        us_holidays['minor_holiday']=0\n",
      "        minor_holidays = ['Martin Luther King, Jr. Day' ,\"Washington's Birthday\" ,'Columbus Day' ,'Veterans Day'] \n",
      "        us_holidays.loc[us_holidays.holiday.isin(minor_holidays),'minor_holiday']=1\n",
      "        us_holidays['major_holiday']=0\n",
      "        major_holidays = [\"New Year's Day\" ,\"Christmas Day\",'Thanksgiving','Memorial Day','Labor Day','Independence Day'] \n",
      "        us_holidays.loc[us_holidays.holiday.isin(major_holidays),'major_holiday']=1\n",
      "        us_holidays['observed_holiday']=0\n",
      "        observed =  us_holidays.holiday.apply(lambda row: True if row[1].endswith(\"(Observed)\") else False)\n",
      "        us_holidays.loc[observed,'observed_holiday']=1\n",
      "        us_holidays = us_holidays.convert_dtypes()\n",
      "        us_holidays.sort_values(self.target_dates).reset_index(drop=True,inplace=True)\n",
      "        us_holidays = us_holidays.set_index(self.target_dates).resample('M').sum().reset_index()\n",
      "\n",
      "        return pd.merge(unseen_dates,us_holidays,on=self.target_dates,how='left')[['minor_holiday','major_holiday','observed_holiday']]\n",
      "\n",
      "    def optimize_SARIMAX(self,parameters_list,train_set,val_set,exog_columns):\n",
      "\n",
      "        val_set1 = val_set.copy()\n",
      "        val_set=val_set[self.target_value].to_numpy()\n",
      "        results=[]\n",
      "        best_adj_mape = float('inf')\n",
      "    #         self.train = self.train.astype(float)\n",
      "        for param in parameters_list:\n",
      "            try:\n",
      "                model=self.fit(train_set[self.target_value].astype(float),train_set.loc[:,exog_columns].astype(float).reset_index(drop=True),param)\n",
      "                fore1=self.predict(model,val_set1.loc[:,exog_columns].astype(float).reset_index(drop=True),self.train.shape[0],self.n_periods)\n",
      "                fore=np.array(fore1)\n",
      "\n",
      "                y_true=np.array(list(train_set[param[6]+param[1]:][self.target_value]))\n",
      "                y_pred=np.array(list(model.fittedvalues[param[6]+param[1]:]))\n",
      "                train_mape=round((self.mean_absolute_percentage_error(y_true,y_pred)),2)\n",
      "                val_mape=round((self.mean_absolute_percentage_error(val_set,fore)),2)\n",
      "                adj_mape = train_mape*len(y_true)/(len(y_true)+len(val_set))+val_mape*len(val_set)/(len(y_true)+len(val_set))\n",
      "                if adj_mape <= best_adj_mape:\n",
      "                    best_adj_mape=adj_mape\n",
      "                    best_model = model    \n",
      "                results.append([param,model.aic,train_mape,val_mape,adj_mape,fore])\n",
      "            except:\n",
      "                continue\n",
      "\n",
      "        result_table=pd.DataFrame(results)\n",
      "\n",
      "        result_table.columns=['parameters','aic','train_mape','val_mape','adj_mape','test_prediction']\n",
      "        val_results = result_table.sort_values(by='adj_mape',ascending=True).reset_index(drop=True).copy()\n",
      "        test_predict = val_results.loc[:5]['test_prediction'].apply(lambda row: pd.Series(row).T).mean()\n",
      "\n",
      "        self.test_prediction = pd.DataFrame(test_predict.values.flatten(),self.test.index,columns=[self.target_value])\n",
      "        return val_results, best_model\n",
      "\n",
      "      \n",
      "\n",
      "\n",
      "    def run_model(self):\n",
      "        exog_columns =  ['minor_holiday','major_holiday', 'observed_holiday']\n",
      "        val_results, best_model = self.optimize_SARIMAX(self.parameters_list,self.train,self.test,exog_columns)\n",
      "        #Model running for test prediction\n",
      "        fitted_val_list=[]\n",
      "\n",
      "        actual_data = self.train.append(self.test)\n",
      "        for param in val_results['parameters'].loc[:5]:\n",
      "            try:\n",
      "\n",
      "                model = self.fit(actual_data[self.target_value],actual_data.loc[:,exog_columns].astype(float).reset_index(drop=True),param)\n",
      "                fore_test=self.predict(model,self.forecast_exogs(self.test).astype(float).reset_index(drop=True),actual_data.shape[0],self.n_periods)\n",
      "                fitted_val_list.append(fore_test.values.flatten())\n",
      "\n",
      "            except:\n",
      "                continue\n",
      "\n",
      "        fitted_val=pd.DataFrame(fitted_val_list,columns=np.arange(1,self.n_periods+1))\n",
      "        fitted_mean=[]\n",
      "        for i in np.arange(1,self.n_periods+1):\n",
      "            fitted_mean.append(fitted_val[i].mean())\n",
      "\n",
      "        unseen_index = pd.date_range(self.test.index[-1]+pd.tseries.offsets.MonthEnd(n=1),\n",
      "              self.test.index[-1]+pd.tseries.offsets.MonthEnd(n=self.n_periods),freq='M')\n",
      "\n",
      "        self.unseen_prediction = pd.DataFrame(fitted_mean,unseen_index,columns=[self.target_value])\n",
      "\n",
      "        #Calculate apes for each test prediction        \n",
      "        self.calculate_apes()\n",
      "        self.train_model_params = val_results['parameters'].loc[:5]            \n",
      "        self.test_model_params = val_results['parameters'].loc[:5]\n",
      "        self.train_mape = val_results['train_mape'].loc[:5].mean()  \n",
      "        self.test_mape = val_results['val_mape'].loc[:5].mean()\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(CT.get_ouput())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SARIMAX'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ck073783\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from model.SARIMAX import SARIMAX\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('model-config.json') as f:\n",
    "  config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['random_state', 'n_periodss', 'not_include_be_list', 'overall_be', 'aggregate_choice', 'target_file', 'target_dates', 'target_value', 'target_items', 'other_target_value', 'raw_data_path', 'processed_file'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>billing_entity</th>\n",
       "      <th>total_charge</th>\n",
       "      <th>count</th>\n",
       "      <th>minor_holiday</th>\n",
       "      <th>major_holiday</th>\n",
       "      <th>observed_holiday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posted_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-31</th>\n",
       "      <td>All Adventist W</td>\n",
       "      <td>7.709414e+08</td>\n",
       "      <td>213504.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-28</th>\n",
       "      <td>All Adventist W</td>\n",
       "      <td>8.748842e+08</td>\n",
       "      <td>241981.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-31</th>\n",
       "      <td>All Adventist W</td>\n",
       "      <td>8.972711e+08</td>\n",
       "      <td>266676.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-30</th>\n",
       "      <td>All Adventist W</td>\n",
       "      <td>8.930693e+08</td>\n",
       "      <td>268530.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-31</th>\n",
       "      <td>All Adventist W</td>\n",
       "      <td>8.659224e+08</td>\n",
       "      <td>261408.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              billing_entity  total_charge     count  minor_holiday  \\\n",
       "posted_date                                                           \n",
       "2015-01-31   All Adventist W  7.709414e+08  213504.0              1   \n",
       "2015-02-28   All Adventist W  8.748842e+08  241981.0              1   \n",
       "2015-03-31   All Adventist W  8.972711e+08  266676.0              0   \n",
       "2015-04-30   All Adventist W  8.930693e+08  268530.0              0   \n",
       "2015-05-31   All Adventist W  8.659224e+08  261408.0              0   \n",
       "\n",
       "             major_holiday  observed_holiday  \n",
       "posted_date                                   \n",
       "2015-01-31               1                 0  \n",
       "2015-02-28               0                 0  \n",
       "2015-03-31               0                 0  \n",
       "2015-04-30               0                 0  \n",
       "2015-05-31               1                 0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "target_dates = 'posted_date'\n",
    "target_values = 'total_charge'\n",
    "target_items = 'billing_entity'\n",
    "transformed_data_path = r'C:\\Users\\CK073783\\OneDrive - Cerner Corporation\\Desktop\\Projects\\Revenue Forecasting\\Versions\\version 2\\data\\processed_data\\All Adventist W\\\\'\n",
    "\n",
    "data_files = os.listdir(transformed_data_path)\n",
    "model_output_path = r'C:\\Users\\CK073783\\OneDrive - Cerner Corporation\\Desktop\\Projects\\Revenue Forecasting\\Versions\\version 2\\data\\model_output\\\\'\n",
    "\n",
    "def filter_data(summary_df):\n",
    "        return summary_df[(summary_df['valid'])&(summary_df['months_missing']==0)][target_items]\n",
    "\n",
    "filename = data_files[0]\n",
    "filehandler = open(transformed_data_path+filename, 'rb') \n",
    "data_object = pickle.load(filehandler)\n",
    "data_date = data_object.summary_df.end_date.max().month_name() +'-'+str(data_object.summary_df.end_date.max().year)\n",
    "\n",
    "filtered_data  = data_object.transform_data[data_object.transform_data[target_items].isin(filter_data(data_object.summary_df))]\n",
    "BE = 'All Adventist W'\n",
    "subset_df = filtered_data[filtered_data[target_items]==BE].reset_index(drop=True)\n",
    "subset_df[target_dates] = pd.to_datetime(subset_df[target_dates]).copy()\n",
    "subset_df.set_index('posted_date',inplace=True)\n",
    "# models = Univariate(BE,data = subset_df[target_value],target_items= target_items,target_value=target_value,target_dates=target_dates)\n",
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['random_state', 'n_periodss', 'not_include_be_list', 'overall_be', 'aggregate_choice', 'target_file', 'target_dates', 'target_value', 'target_items', 'other_target_value', 'raw_data_path', 'processed_file', 'parameters_list', 'train', 'test'])\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "def split_train_test(subset_df):\n",
    "        return subset_df[:-3],subset_df[-3:]\n",
    "train,test = split_train_test(subset_df)\n",
    "p=range(0,2)\n",
    "d=range(0,1)\n",
    "q=range(0,2)\n",
    "P=range(0,2)\n",
    "D=range(0,1)\n",
    "Q=range(0,2)\n",
    "s=(3,6,12)\n",
    "\n",
    "parameters=product(p,d,q,P,D,Q,s)\n",
    "parameters_list=list(parameters)\n",
    "\n",
    "# use_arma_errors=[True,False]\n",
    "# use_box_cox=[True,False]\n",
    "# use_trend=[True,False]\n",
    "# use_damped_trend=[True,False]  \n",
    "\n",
    "# parameters=product(use_arma_errors,use_box_cox,use_trend,use_damped_trend)\n",
    "# parameters_list=list(parameters)\n",
    "\n",
    "def check(**kwargs):\n",
    "    print(kwargs.keys())\n",
    "config['parameters_list'] = parameters_list\n",
    "config['train'] = train\n",
    "config['test'] = test\n",
    "check(**config)\n",
    "obj = SARIMAX(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.003346609577044, 5.2054298437018325, 16.9135002366496]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.apes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.unseen_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
